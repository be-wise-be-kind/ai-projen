"""
Purpose: Template for Celery background task implementation with retry logic and progress tracking

Scope: Asynchronous task processing, background job execution, distributed task queuing

Overview: Generates Python module for Celery distributed task processing with comprehensive
    patterns for task execution, error handling, and monitoring. Provides three task variants:
    standard task with manual retry logic and error handling, progress-tracking task with
    state updates for long-running operations, and auto-retry task with exponential backoff
    for resilient operations. Each task includes logging, result handling, and configurable
    retry policies. Follows Celery best practices for distributed task execution.

Dependencies: Celery (distributed task queue), celery.utils.log for task logging

Exports: Three task function variants - basic task with manual retry, progress-tracking task,
    and auto-retry task with exponential backoff

Placeholders:
    - {{MODULE_NAME}}: Name of the module containing tasks (e.g., "notifications", "email")
    - {{DESCRIPTION}}: Brief description of what tasks in module handle
    - {{TASK_NAME}}: Base name for task functions (e.g., "send_email", "process_data")
    - {{TASK_DESCRIPTION}}: Description of what the task does
    - {{PARAMETERS}}: Task function parameters (e.g., "user_id: int, data: dict")
    - {{PARAMETER_DESCRIPTIONS}}: Documentation for each parameter

Usage: Copy template to target location, replace all {{PLACEHOLDERS}}, customize implementation

Related: Celery documentation, distributed task queue patterns, async processing best practices

Implementation: Uses Celery shared_task decorator, implements retry policies, progress tracking
    with state updates, automatic retry with exponential backoff and jitter, comprehensive logging
"""

from celery import shared_task
from celery.utils.log import get_task_logger
from typing import Any
import time

logger = get_task_logger(__name__)


@shared_task(bind=True, max_retries=3, default_retry_delay=60)
def {{TASK_NAME}}(self, {{PARAMETERS}}) -> dict[str, Any]:
    """{{TASK_DESCRIPTION}}.

    Args:
        {{PARAMETER_DESCRIPTIONS}}

    Returns:
        Task result dictionary

    Raises:
        Exception: If task fails after retries
    """
    try:
        logger.info(f"Starting {{TASK_NAME}} with {{PARAMETERS}}")

        # TODO: Implement task logic
        # Example:
        # result = process_data(data)

        logger.info(f"{{TASK_NAME}} completed successfully")
        return {
            "status": "success",
            "task_id": self.request.id,
            # TODO: Add result data
        }

    except Exception as exc:
        logger.error(f"Error in {{TASK_NAME}}: {exc}")
        # Retry the task
        raise self.retry(exc=exc)


@shared_task(bind=True)
def {{TASK_NAME}}_with_progress(self, {{PARAMETERS}}) -> dict[str, Any]:
    """{{TASK_DESCRIPTION}} with progress tracking.

    Args:
        {{PARAMETER_DESCRIPTIONS}}

    Returns:
        Task result
    """
    logger.info(f"Starting {{TASK_NAME}}_with_progress")

    # Update task state for progress tracking
    total_steps = 100
    for i in range(total_steps):
        # Update progress
        self.update_state(
            state="PROGRESS",
            meta={
                "current": i,
                "total": total_steps,
                "status": f"Processing step {i}/{total_steps}"
            }
        )

        # TODO: Implement step logic
        time.sleep(0.1)

    logger.info(f"{{TASK_NAME}}_with_progress completed")
    return {
        "status": "success",
        "task_id": self.request.id
    }


@shared_task(
    autoretry_for=(Exception,),
    retry_kwargs={"max_retries": 5},
    retry_backoff=True,
    retry_jitter=True
)
def {{TASK_NAME}}_with_auto_retry({{PARAMETERS}}) -> dict[str, Any]:
    """{{TASK_DESCRIPTION}} with automatic retry.

    Automatically retries on any exception with exponential backoff.

    Args:
        {{PARAMETER_DESCRIPTIONS}}

    Returns:
        Task result
    """
    logger.info(f"Executing {{TASK_NAME}}_with_auto_retry")

    # TODO: Implement task logic that might fail
    # Example: External API call
    # response = requests.get(url, timeout=30)
    # response.raise_for_status()

    return {
        "status": "success"
    }
